{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e68efe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ğŸ íŠœë‹ ì „ ë² ì´ìŠ¤ë¼ì¸ ì ìˆ˜ ---\n",
      "ì •í™•ë„: 0.9561\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "base_model = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "base_model.fit(X_train, y_train)\n",
    "base_pred = base_model.predict(X_test)\n",
    "\n",
    "print(f\"--- ğŸ íŠœë‹ ì „ ë² ì´ìŠ¤ë¼ì¸ ì ìˆ˜ ---\")\n",
    "print(f\"ì •í™•ë„: {accuracy_score(y_test, base_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f052c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "pred_rf = model_rf.predict(X_test)\n",
    "score_rf = accuracy_score(y_test, pred_rf)\n",
    "print(round(score_rf, 3))\n",
    "\n",
    "report_rf = classification_report(y_test, pred_rf)\n",
    "print(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d273ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "\n",
      "--- ğŸ† Grid Search ê²°ê³¼ ---\n",
      "ìµœì ì˜ íŒŒë¼ë¯¸í„°: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "ìµœê³ ì˜ ì ìˆ˜(CV): 0.9670\n",
      "í…ŒìŠ¤íŠ¸ì…‹ ìµœì¢… ì •í™•ë„: 0.9561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=XGBClassifier(eval_metric='logloss', random_state=42), param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n--- ğŸ† Grid Search ê²°ê³¼ ---\")\n",
    "print(f\"ìµœì ì˜ íŒŒë¼ë¯¸í„°: {grid_search.best_params_}\")\n",
    "print(f\"ìµœê³ ì˜ ì ìˆ˜(CV): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "final_pred = best_model.predict(X_test)\n",
    "print(f\"í…ŒìŠ¤íŠ¸ì…‹ ìµœì¢… ì •í™•ë„: {accuracy_score(y_test, final_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63973d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-17 17:23:47,036] A new study created in memory with name: no-name-dc6076a5-3fee-4f8f-aebe-8b7a81b525e7\n",
      "[I 2025-12-17 17:23:47,390] Trial 0 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 266, 'max_depth': 4, 'learning_rate': 0.06407400625814322, 'subsample': 0.7015958874700193, 'colsample_bytree': 0.7291790340593769}. Best is trial 0 with value: 0.9736842105263158.\n",
      "[I 2025-12-17 17:23:47,600] Trial 1 finished with value: 0.956140350877193 and parameters: {'n_estimators': 126, 'max_depth': 7, 'learning_rate': 0.12362337858439122, 'subsample': 0.9797246991786137, 'colsample_bytree': 0.7176853573052926}. Best is trial 0 with value: 0.9736842105263158.\n",
      "[I 2025-12-17 17:23:47,925] Trial 2 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 281, 'max_depth': 6, 'learning_rate': 0.16455209695277848, 'subsample': 0.8127223828162102, 'colsample_bytree': 0.9838335960517959}. Best is trial 0 with value: 0.9736842105263158.\n",
      "[I 2025-12-17 17:23:48,236] Trial 3 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 243, 'max_depth': 10, 'learning_rate': 0.1004059563999677, 'subsample': 0.5165743156159903, 'colsample_bytree': 0.609249180725949}. Best is trial 0 with value: 0.9736842105263158.\n",
      "[I 2025-12-17 17:23:48,589] Trial 4 finished with value: 0.9649122807017544 and parameters: {'n_estimators': 295, 'max_depth': 6, 'learning_rate': 0.08457532614684846, 'subsample': 0.8491871529783732, 'colsample_bytree': 0.6650671961808015}. Best is trial 0 with value: 0.9736842105263158.\n",
      "[I 2025-12-17 17:23:48,841] Trial 5 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 184, 'max_depth': 4, 'learning_rate': 0.05379998805107258, 'subsample': 0.5131362922981773, 'colsample_bytree': 0.5286273576352278}. Best is trial 0 with value: 0.9736842105263158.\n",
      "[I 2025-12-17 17:23:49,138] Trial 6 finished with value: 0.9824561403508771 and parameters: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.230041918257328, 'subsample': 0.6294061549358219, 'colsample_bytree': 0.9359504413277289}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:49,272] Trial 7 finished with value: 0.956140350877193 and parameters: {'n_estimators': 53, 'max_depth': 8, 'learning_rate': 0.10727334865394933, 'subsample': 0.893784587199909, 'colsample_bytree': 0.7839071608423058}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:49,594] Trial 8 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 265, 'max_depth': 6, 'learning_rate': 0.12123181584551015, 'subsample': 0.5396455054773346, 'colsample_bytree': 0.5676587805431655}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:49,767] Trial 9 finished with value: 0.956140350877193 and parameters: {'n_estimators': 88, 'max_depth': 3, 'learning_rate': 0.022259341100814206, 'subsample': 0.7300083624284804, 'colsample_bytree': 0.7786118106123399}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:50,001] Trial 10 finished with value: 0.9649122807017544 and parameters: {'n_estimators': 192, 'max_depth': 9, 'learning_rate': 0.24841674727329027, 'subsample': 0.626328729652043, 'colsample_bytree': 0.9951763977531366}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:50,264] Trial 11 finished with value: 0.9649122807017544 and parameters: {'n_estimators': 228, 'max_depth': 4, 'learning_rate': 0.21593151879620687, 'subsample': 0.6847043456989677, 'colsample_bytree': 0.8702196242164055}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:50,466] Trial 12 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 140, 'max_depth': 4, 'learning_rate': 0.1878530491723695, 'subsample': 0.6309376188427835, 'colsample_bytree': 0.9218656604918061}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:50,702] Trial 13 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 213, 'max_depth': 5, 'learning_rate': 0.2927743082641884, 'subsample': 0.6138741095839039, 'colsample_bytree': 0.8683587891957744}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:50,889] Trial 14 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 154, 'max_depth': 3, 'learning_rate': 0.24686377142276578, 'subsample': 0.7444574478943049, 'colsample_bytree': 0.7227125214966631}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:51,345] Trial 15 finished with value: 0.956140350877193 and parameters: {'n_estimators': 253, 'max_depth': 5, 'learning_rate': 0.023327251378273184, 'subsample': 0.6864900120457683, 'colsample_bytree': 0.8253682778366662}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:51,565] Trial 16 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 209, 'max_depth': 5, 'learning_rate': 0.2912191458136121, 'subsample': 0.592164708856213, 'colsample_bytree': 0.6679717592296476}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:51,795] Trial 17 finished with value: 0.9649122807017544 and parameters: {'n_estimators': 161, 'max_depth': 7, 'learning_rate': 0.17682199847042024, 'subsample': 0.7785315348919992, 'colsample_bytree': 0.9052820165925805}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:51,959] Trial 18 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 113, 'max_depth': 3, 'learning_rate': 0.20706541253727118, 'subsample': 0.6853218371004979, 'colsample_bytree': 0.6643249432349262}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:52,286] Trial 19 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 224, 'max_depth': 5, 'learning_rate': 0.06381986017891612, 'subsample': 0.5695953096689339, 'colsample_bytree': 0.8313999587231427}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:52,572] Trial 20 finished with value: 0.9649122807017544 and parameters: {'n_estimators': 268, 'max_depth': 4, 'learning_rate': 0.23490890997680489, 'subsample': 0.6599576980067964, 'colsample_bytree': 0.9447191171435473}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:52,907] Trial 21 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 297, 'max_depth': 6, 'learning_rate': 0.15410183105516598, 'subsample': 0.8034356319102359, 'colsample_bytree': 0.9991282154583021}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:53,232] Trial 22 finished with value: 0.9649122807017544 and parameters: {'n_estimators': 276, 'max_depth': 7, 'learning_rate': 0.15582296203805765, 'subsample': 0.8249748612162078, 'colsample_bytree': 0.95444140841741}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:53,607] Trial 23 finished with value: 0.9649122807017544 and parameters: {'n_estimators': 240, 'max_depth': 6, 'learning_rate': 0.137656434911761, 'subsample': 0.9130621913628875, 'colsample_bytree': 0.961984480149329}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:53,941] Trial 24 finished with value: 0.9649122807017544 and parameters: {'n_estimators': 283, 'max_depth': 8, 'learning_rate': 0.2702422265403127, 'subsample': 0.7237840416721192, 'colsample_bytree': 0.8837233942019798}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:54,208] Trial 25 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 191, 'max_depth': 5, 'learning_rate': 0.17435024568270097, 'subsample': 0.7658852392537565, 'colsample_bytree': 0.8141584564664278}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:54,493] Trial 26 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 260, 'max_depth': 4, 'learning_rate': 0.21080932608659436, 'subsample': 0.8616313662976978, 'colsample_bytree': 0.7464911560297489}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:54,806] Trial 27 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 167, 'max_depth': 8, 'learning_rate': 0.054021965903712985, 'subsample': 0.7182175473996953, 'colsample_bytree': 0.6988514123922295}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:55,077] Trial 28 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 206, 'max_depth': 5, 'learning_rate': 0.1508814296796573, 'subsample': 0.6591181191618609, 'colsample_bytree': 0.9083286380425398}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:55,431] Trial 29 finished with value: 0.9649122807017544 and parameters: {'n_estimators': 283, 'max_depth': 7, 'learning_rate': 0.12571887482431243, 'subsample': 0.97106140968614, 'colsample_bytree': 0.6254009188646974}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:55,644] Trial 30 finished with value: 0.9649122807017544 and parameters: {'n_estimators': 125, 'max_depth': 6, 'learning_rate': 0.19429483942418213, 'subsample': 0.8080966157144596, 'colsample_bytree': 0.9771631795397121}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:55,955] Trial 31 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 242, 'max_depth': 10, 'learning_rate': 0.09097307306929753, 'subsample': 0.5020959632155768, 'colsample_bytree': 0.5864789004310058}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:56,295] Trial 32 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 256, 'max_depth': 10, 'learning_rate': 0.08110029950766873, 'subsample': 0.5335566008550349, 'colsample_bytree': 0.6111609073353207}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:56,650] Trial 33 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 299, 'max_depth': 9, 'learning_rate': 0.10655032170808226, 'subsample': 0.5712480142908583, 'colsample_bytree': 0.6950504537386759}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:57,018] Trial 34 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 230, 'max_depth': 6, 'learning_rate': 0.03825537099748539, 'subsample': 0.5807825675425923, 'colsample_bytree': 0.5043325507802447}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:57,342] Trial 35 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 246, 'max_depth': 7, 'learning_rate': 0.07249225305865334, 'subsample': 0.5312147720421797, 'colsample_bytree': 0.5502244999493082}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:57,704] Trial 36 finished with value: 0.9649122807017544 and parameters: {'n_estimators': 277, 'max_depth': 9, 'learning_rate': 0.10190997432428293, 'subsample': 0.84157192669626, 'colsample_bytree': 0.7792417096739903}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:57,872] Trial 37 finished with value: 0.956140350877193 and parameters: {'n_estimators': 64, 'max_depth': 4, 'learning_rate': 0.040109941030144675, 'subsample': 0.881252577736532, 'colsample_bytree': 0.6553595086732341}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:58,134] Trial 38 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 179, 'max_depth': 3, 'learning_rate': 0.09137693545378311, 'subsample': 0.7771453974560861, 'colsample_bytree': 0.7441897382058836}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:58,582] Trial 39 finished with value: 0.956140350877193 and parameters: {'n_estimators': 198, 'max_depth': 8, 'learning_rate': 0.01101104112776928, 'subsample': 0.6440575536765096, 'colsample_bytree': 0.6255030734867275}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:58,945] Trial 40 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 221, 'max_depth': 6, 'learning_rate': 0.1182259633258134, 'subsample': 0.6984774384452709, 'colsample_bytree': 0.9391422176681699}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:59,237] Trial 41 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.05807062085334073, 'subsample': 0.5046131587875845, 'colsample_bytree': 0.5025496601468131}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:59,493] Trial 42 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 145, 'max_depth': 4, 'learning_rate': 0.04588659456833831, 'subsample': 0.5409318578415153, 'colsample_bytree': 0.5327283488504764}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:23:59,723] Trial 43 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 174, 'max_depth': 5, 'learning_rate': 0.22568473224118654, 'subsample': 0.6195811246928256, 'colsample_bytree': 0.57645114107508}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:24:00,078] Trial 44 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 268, 'max_depth': 3, 'learning_rate': 0.07635562745574773, 'subsample': 0.5514695652732079, 'colsample_bytree': 0.534861694699145}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:24:00,607] Trial 45 finished with value: 0.9649122807017544 and parameters: {'n_estimators': 287, 'max_depth': 5, 'learning_rate': 0.027927289294817033, 'subsample': 0.6012272148065376, 'colsample_bytree': 0.6020680623545014}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:24:00,985] Trial 46 finished with value: 0.9649122807017544 and parameters: {'n_estimators': 234, 'max_depth': 4, 'learning_rate': 0.0668646486187758, 'subsample': 0.5118152402735167, 'colsample_bytree': 0.8488719574225784}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:24:01,278] Trial 47 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 213, 'max_depth': 3, 'learning_rate': 0.13262139448041435, 'subsample': 0.6561497523306715, 'colsample_bytree': 0.7913733582236581}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:24:01,557] Trial 48 finished with value: 0.9736842105263158 and parameters: {'n_estimators': 250, 'max_depth': 5, 'learning_rate': 0.26576051937220785, 'subsample': 0.5538552286527963, 'colsample_bytree': 0.9791136457527889}. Best is trial 6 with value: 0.9824561403508771.\n",
      "[I 2025-12-17 17:24:01,818] Trial 49 finished with value: 0.9649122807017544 and parameters: {'n_estimators': 149, 'max_depth': 6, 'learning_rate': 0.0964253297645534, 'subsample': 0.7450971522612483, 'colsample_bytree': 0.7201628854911923}. Best is trial 6 with value: 0.9824561403508771.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ğŸ§  Optuna ê²°ê³¼ ---\n",
      "ê°€ì¥ ì¢‹ì€ ì ìˆ˜: 0.9825\n",
      "ê·¸ë•Œì˜ íŒŒë¼ë¯¸í„°: {'n_estimators': 187, 'max_depth': 5, 'learning_rate': 0.230041918257328, 'subsample': 0.6294061549358219, 'colsample_bytree': 0.9359504413277289}\n"
     ]
    }
   ],
   "source": [
    "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ì—†ìœ¼ë©´ ì‹¤í–‰)\n",
    "# !pip install optuna \n",
    "\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 2. ìµœì í™”í•  ëª©í‘œ í•¨ìˆ˜ ì •ì˜ (Objective Function)\n",
    "def objective(trial):\n",
    "    # íŠœë‹í•  í•˜ì´í¼íŒŒë¼ë¯¸í„° ë²”ìœ„ ì„¤ì •\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0), # ë°ì´í„° ìƒ˜í”Œë§ ë¹„ìœ¨\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0) # ì»¬ëŸ¼ ìƒ˜í”Œë§ ë¹„ìœ¨\n",
    "    }\n",
    "    \n",
    "    # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
    "    model = XGBClassifier(**params, random_state=42, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # ê²€ì¦ (ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ Testì…‹ ì ìˆ˜ë¥¼ ë¦¬í„´í•˜ì§€ë§Œ, ì›ë˜ëŠ” Validationì…‹ì„ ì¨ì•¼ í•¨)\n",
    "    pred = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, pred)\n",
    "    \n",
    "    return score\n",
    "\n",
    "# 3. ìŠ¤í„°ë”” ìƒì„± ë° ìµœì í™” ì‹¤í–‰\n",
    "study = optuna.create_study(direction='maximize') # ì ìˆ˜ë¥¼ 'ìµœëŒ€í™”' í•´ë¼\n",
    "study.optimize(objective, n_trials=50) # 50ë²ˆ ì‹œë„í•´ë¼\n",
    "\n",
    "print(f\"\\n--- ğŸ§  Optuna ê²°ê³¼ ---\")\n",
    "print(f\"ê°€ì¥ ì¢‹ì€ ì ìˆ˜: {study.best_value:.4f}\")\n",
    "print(f\"ê·¸ë•Œì˜ íŒŒë¼ë¯¸í„°: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "819ca4b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\visualization\\_plotly_imports.py:7\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m try_import() \u001b[38;5;28;01mas\u001b[39;00m _imports:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m plotly_version\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptuna\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_optimization_history, plot_param_importances\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 1. ì ìˆ˜ê°€ ì–´ë–»ê²Œ ì˜¬ë¼ê°€ëŠ”ì§€ ë³´ì—¬ì¤Œ (ìš°ìƒí–¥í•˜ë©´ ì„±ê³µ!)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mplot_optimization_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m)\u001b[49m.show()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 2. ì–´ë–¤ íŒŒë¼ë¯¸í„°ê°€ ì ìˆ˜ì— ê°€ì¥ í° ì˜í–¥ì„ ì¤¬ëŠ”ì§€ ë³´ì—¬ì¤Œ (ì¤‘ìš”ë„)\u001b[39;00m\n\u001b[32m      7\u001b[39m plot_param_importances(study).show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\visualization\\_optimization_history.py:200\u001b[39m, in \u001b[36mplot_optimization_history\u001b[39m\u001b[34m(study, target, target_name, error_bar)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_optimization_history\u001b[39m(\n\u001b[32m    173\u001b[39m     study: Study | Sequence[Study],\n\u001b[32m    174\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    177\u001b[39m     error_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    178\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mgo.Figure\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    179\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Plot optimization history of all trials in a study.\u001b[39;00m\n\u001b[32m    180\u001b[39m \n\u001b[32m    181\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    197\u001b[39m \u001b[33;03m        A :class:`plotly.graph_objects.Figure` object.\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[43m_imports\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     info_list = _get_optimization_history_info_list(study, target, target_name, error_bar)\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_optimization_history_plot(info_list, target_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\_imports.py:97\u001b[39m, in \u001b[36m_DeferredImportExceptionContextManager.check\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._deferred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     96\u001b[39m     exc_value, message = \u001b[38;5;28mself\u001b[39m._deferred\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc_value\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "\n",
    "# 1. ì ìˆ˜ê°€ ì–´ë–»ê²Œ ì˜¬ë¼ê°€ëŠ”ì§€ ë³´ì—¬ì¤Œ (ìš°ìƒí–¥í•˜ë©´ ì„±ê³µ!)\n",
    "plot_optimization_history(study).show()\n",
    "\n",
    "# 2. ì–´ë–¤ íŒŒë¼ë¯¸í„°ê°€ ì ìˆ˜ì— ê°€ì¥ í° ì˜í–¥ì„ ì¤¬ëŠ”ì§€ ë³´ì—¬ì¤Œ (ì¤‘ìš”ë„)\n",
    "plot_param_importances(study).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
